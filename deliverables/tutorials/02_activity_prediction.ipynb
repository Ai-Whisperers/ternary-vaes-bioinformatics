{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Activity Prediction with P-adic Embeddings\n",
    "\n",
    "This notebook demonstrates how to use the Ternary VAE's p-adic embeddings\n",
    "to predict antimicrobial peptide activity.\n",
    "\n",
    "## Contents\n",
    "1. Load the Codon Encoder\n",
    "2. Embed Peptide Sequences\n",
    "3. Train an Activity Predictor\n",
    "4. Predict Activity for New Sequences\n",
    "5. Analyze Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project paths\n",
    "deliverables_path = Path.cwd().parent\n",
    "project_root = deliverables_path.parent\n",
    "sys.path.insert(0, str(deliverables_path))\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load the Codon Encoder\n",
    "\n",
    "The codon encoder maps amino acid sequences into a 16-dimensional hyperbolic\n",
    "embedding space where radial position encodes 3-adic valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared import CodonEncoder\n",
    "\n",
    "# Initialize the codon encoder\n",
    "# This loads the pretrained VAE checkpoint\n",
    "encoder = CodonEncoder()\n",
    "print(f\"Codon encoder initialized\")\n",
    "print(f\"  Latent dimension: {encoder.latent_dim}\")\n",
    "print(f\"  Device: {encoder.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Embed Peptide Sequences\n",
    "\n",
    "Convert peptide sequences into p-adic embeddings. Each amino acid is mapped\n",
    "to a point in hyperbolic space, and the sequence embedding is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example antimicrobial peptides with known activity\n",
    "peptides = {\n",
    "    \"Magainin 2\": {\"sequence\": \"GIGKFLHSAKKFGKAFVGEIMNS\", \"mic\": 10.0},\n",
    "    \"Melittin\": {\"sequence\": \"GIGAVLKVLTTGLPALISWIKRKRQQ\", \"mic\": 1.0},\n",
    "    \"LL-37\": {\"sequence\": \"LLGDFFRKSKEKIGKEFKRIVQRIKDFLRNLVPRTES\", \"mic\": 5.0},\n",
    "    \"Indolicidin\": {\"sequence\": \"ILPWKWPWWPWRR\", \"mic\": 8.0},\n",
    "    \"Cecropin A\": {\"sequence\": \"KWKLFKKIEKVGQNIRDGIIKAGPAVAVVGQATQIAK\", \"mic\": 2.0},\n",
    "    \"Defensin\": {\"sequence\": \"ACYCRIPACIAGERRYGTCIYQGRLWAFCC\", \"mic\": 15.0},\n",
    "    \"Cathelicidin\": {\"sequence\": \"GRFKRFRKKFKKLFKKLSPVIPLLHL\", \"mic\": 4.0},\n",
    "    \"Thanatin\": {\"sequence\": \"GSKKPVPIIYCNRRTGKCQRM\", \"mic\": 12.0},\n",
    "}\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = {}\n",
    "for name, data in peptides.items():\n",
    "    emb = encoder.encode_sequence(data[\"sequence\"])\n",
    "    embeddings[name] = {\n",
    "        \"embedding\": emb,\n",
    "        \"radius\": np.linalg.norm(emb),\n",
    "        \"mic\": data[\"mic\"],\n",
    "    }\n",
    "    print(f\"{name:<15} radius={embeddings[name]['radius']:.4f}, MIC={data['mic']:.1f} uM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the embedding space\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Extract data for plotting\n",
    "names = list(embeddings.keys())\n",
    "radii = [embeddings[n][\"radius\"] for n in names]\n",
    "mics = [embeddings[n][\"mic\"] for n in names]\n",
    "\n",
    "# Compute correlation\n",
    "corr, pval = spearmanr(radii, mics)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scatter = ax.scatter(radii, mics, s=100, c=np.log10(mics), cmap=\"viridis\")\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    ax.annotate(name, (radii[i], mics[i]), fontsize=9, ha=\"left\", va=\"bottom\")\n",
    "\n",
    "ax.set_xlabel(\"Embedding Radius\", fontsize=12)\n",
    "ax.set_ylabel(\"MIC (uM)\", fontsize=12)\n",
    "ax.set_title(f\"P-adic Radius vs Antimicrobial Activity\\nSpearman rho={corr:.2f}, p={pval:.3f}\", fontsize=14)\n",
    "plt.colorbar(scatter, label=\"log10(MIC)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Train an Activity Predictor\n",
    "\n",
    "Use the p-adic embeddings as features for predicting antimicrobial activity.\n",
    "We'll use a simple random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare training data\n",
    "X = np.array([embeddings[n][\"embedding\"] for n in names])\n",
    "y = np.log10(np.array([embeddings[n][\"mic\"] for n in names]))  # Log-transform MIC\n",
    "\n",
    "print(f\"Training data shape: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# Train model with leave-one-out cross-validation\n",
    "loo = LeaveOneOut()\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "y_pred = np.zeros_like(y)\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    model.fit(X[train_idx], y[train_idx])\n",
    "    y_pred[test_idx] = model.predict(X[test_idx])\n",
    "\n",
    "# Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"\\nLeave-one-out cross-validation:\")\n",
    "print(f\"  RMSE: {rmse:.3f} log10(uM)\")\n",
    "print(f\"  R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.scatter(y, y_pred, s=100, alpha=0.7)\n",
    "\n",
    "# Add peptide names\n",
    "for i, name in enumerate(names):\n",
    "    ax.annotate(name, (y[i], y_pred[i]), fontsize=9, ha=\"left\", va=\"bottom\")\n",
    "\n",
    "# Add diagonal line\n",
    "lims = [min(y.min(), y_pred.min()) - 0.1, max(y.max(), y_pred.max()) + 0.1]\n",
    "ax.plot(lims, lims, \"k--\", alpha=0.5, label=\"Perfect prediction\")\n",
    "\n",
    "ax.set_xlabel(\"Actual log10(MIC)\", fontsize=12)\n",
    "ax.set_ylabel(\"Predicted log10(MIC)\", fontsize=12)\n",
    "ax.set_title(f\"Activity Prediction (LOO CV)\\nRMSE={rmse:.3f}, R2={r2:.3f}\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Predict Activity for New Sequences\n",
    "\n",
    "Use the trained model to predict activity for novel peptide sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on all data\n",
    "final_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Predict for new sequences\n",
    "new_peptides = [\n",
    "    \"KLWKKWKKWLK\",      # Synthetic cationic peptide\n",
    "    \"GIGKFLHSAGK\",      # Magainin variant\n",
    "    \"RRWWRRWWRR\",       # Arg-Trp rich peptide\n",
    "]\n",
    "\n",
    "print(\"Predictions for new peptides:\")\n",
    "print(\"-\" * 50)\n",
    "for seq in new_peptides:\n",
    "    emb = encoder.encode_sequence(seq)\n",
    "    log_mic_pred = final_model.predict(emb.reshape(1, -1))[0]\n",
    "    mic_pred = 10 ** log_mic_pred\n",
    "    radius = np.linalg.norm(emb)\n",
    "    print(f\"{seq:<20} radius={radius:.4f}, predicted MIC={mic_pred:.1f} uM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Analyze Embedding Space\n",
    "\n",
    "Visualize the p-adic embedding dimensions to understand what features\n",
    "the VAE has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "importances = final_model.feature_importances_\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(range(len(importances)), importances)\n",
    "ax.set_xlabel(\"Embedding Dimension\", fontsize=12)\n",
    "ax.set_ylabel(\"Feature Importance\", fontsize=12)\n",
    "ax.set_title(\"P-adic Embedding Dimension Importance for Activity Prediction\", fontsize=14)\n",
    "ax.set_xticks(range(len(importances)))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top dimensions\n",
    "top_dims = np.argsort(importances)[::-1][:5]\n",
    "print(f\"\\nTop 5 important dimensions: {top_dims}\")\n",
    "for dim in top_dims:\n",
    "    print(f\"  Dim {dim}: importance={importances[dim]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D for visualization using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=y, s=200, cmap=\"coolwarm\", edgecolor=\"k\")\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    ax.annotate(name, (X_2d[i, 0], X_2d[i, 1]), fontsize=10, ha=\"left\", va=\"bottom\")\n",
    "\n",
    "ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)\", fontsize=12)\n",
    "ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)\", fontsize=12)\n",
    "ax.set_title(\"Peptide Embedding Space (PCA)\", fontsize=14)\n",
    "plt.colorbar(scatter, label=\"log10(MIC)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Combine with Biophysical Features\n",
    "\n",
    "Combine p-adic embeddings with traditional biophysical features for\n",
    "improved predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared import compute_peptide_properties, compute_ml_features\n",
    "\n",
    "# Combine features\n",
    "def get_combined_features(sequence, encoder):\n",
    "    \"\"\"Get combined p-adic + biophysical features.\"\"\"\n",
    "    # P-adic embedding\n",
    "    padic_emb = encoder.encode_sequence(sequence)\n",
    "    \n",
    "    # Biophysical features\n",
    "    props = compute_peptide_properties(sequence)\n",
    "    bio_features = np.array([\n",
    "        props[\"length\"],\n",
    "        props[\"net_charge\"],\n",
    "        props[\"hydrophobicity\"],\n",
    "        props[\"hydrophobic_ratio\"],\n",
    "        props[\"cationic_ratio\"],\n",
    "    ])\n",
    "    \n",
    "    return np.concatenate([padic_emb, bio_features])\n",
    "\n",
    "# Build combined feature matrix\n",
    "X_combined = np.array([get_combined_features(peptides[n][\"sequence\"], encoder) for n in names])\n",
    "print(f\"Combined feature shape: {X_combined.shape}\")\n",
    "print(f\"  P-adic dimensions: {X.shape[1]}\")\n",
    "print(f\"  Biophysical features: 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "models = {\n",
    "    \"P-adic only\": (X, RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    \"Combined\": (X_combined, RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    \"Combined (GB)\": (X_combined, GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
    "}\n",
    "\n",
    "print(\"Model comparison (LOO CV):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, (features, model) in models.items():\n",
    "    y_pred = np.zeros_like(y)\n",
    "    for train_idx, test_idx in loo.split(features):\n",
    "        model.fit(features[train_idx], y[train_idx])\n",
    "        y_pred[test_idx] = model.predict(features[test_idx])\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    print(f\"{name:<20} RMSE={rmse:.3f}, R2={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Codon Encoder**: Loading and using the pretrained p-adic encoder\n",
    "2. **Sequence Embedding**: Converting peptides to 16-dimensional vectors\n",
    "3. **Activity Prediction**: Training ML models on embeddings\n",
    "4. **Novel Predictions**: Predicting activity for new sequences\n",
    "5. **Feature Analysis**: Understanding which dimensions are important\n",
    "6. **Feature Combination**: Combining p-adic with biophysical features\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- The p-adic embedding radius correlates with antimicrobial activity\n",
    "- Combining p-adic embeddings with biophysical features improves predictions\n",
    "- Certain embedding dimensions capture activity-relevant information\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Train on larger datasets (DRAMP, APD3)\n",
    "- Add uncertainty quantification\n",
    "- Use for peptide optimization with genetic algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

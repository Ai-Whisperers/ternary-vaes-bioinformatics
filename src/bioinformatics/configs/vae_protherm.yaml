# DDG VAE-ProTherm Configuration
# ==============================================
# Configuration for training the ProTherm high-quality specialist VAE.
#
# Target: Maximum performance on curated high-quality data.
# Expected Spearman: ~0.90+ (cleaner data advantage)

# Inherit from base
defaults:
  - base

# Training parameters optimized for curated data
training:
  epochs: 200  # More epochs for smaller, cleaner data
  batch_size: 16  # Smaller batch for smaller dataset
  learning_rate: 5.0e-5  # Slower for cleaner data
  weight_decay: 1.0e-5
  early_stopping_patience: 30

  # Gentle warmup for cleaner data
  beta_schedule: warmup
  beta_warmup_epochs: 20

# ProTherm specialist architecture (larger capacity)
model:
  # Input: 18 (with structural features)
  input_dim: 18
  hidden_dim: 128  # Larger for cleaner data
  latent_dim: 32   # Larger latent for richer representation
  n_layers: 2

  activation: silu
  dropout: 0.05  # Less dropout for cleaner data
  use_layer_norm: true

  # Hyperbolic features
  use_hyperbolic: true
  hyperbolic_dim: 4

  # Lower KL weight for reconstruction focus
  beta: 0.5

# Validation strategy (LOO for small curated set)
validation:
  val_ratio: 0.2
  use_loo: true  # Leave-one-out for gold standard evaluation

# Data settings
data:
  dataset: protherm_curated
  include_structural: true  # Use secondary structure, RSA

# Output
output:
  model_name: vae_protherm
  experiment_dir: ${output.base_dir}/vae_protherm
